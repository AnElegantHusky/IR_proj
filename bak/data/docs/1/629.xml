<?xml version='1.0' encoding='utf-8'?>
<doc><id>629</id><url>https://docs.python.org/zh-cn/3/howto/logging-cookbook.html</url><title>日志操作手册</title><body>Vinay Sajip &lt;vinay_sajip at red-dove dot com&gt;
本页包含了许多日志记录相关的概念，这些概念在过去一直被认为很有用。
多次调用 logging.getLogger('someLogger') 时会返回对同一个 logger 对象的引用。 这不仅是在同一个模块中，在其他模块调用也是如此，只要是在同一个 Python 解释器进程中。 是应该引用同一个对象，此外，应用程序也可以在一个模块中定义和配置父 logger，而在单独的模块中创建（但不配置）子 logger，对子 logger 的所有调用都将传给父 logger。 这里是主模块:
这里是辅助模块:
输出结果会像这样:
在多个线程中记录日志并不需要特殊的处理，以下示例展示了如何在主（初始）线程和另一个线程中记录日志:
脚本会运行输出类似下面的内容:
这表明不同线程的日志像期望的那样穿插输出，当然更多的线程也会像这样输出。
日志记录器是普通的Python对象。addHandler() 方法对可以添加的日志处理器的数量没有限制。有时候，应用程序需要将所有严重性的所有消息记录到一个文本文件，而将错误或更高等级的消息输出到控制台。要进行这样的设定，只需配置适当的日志处理器即可。在应用程序代码中，记录日志的调用将保持不变。以下是对之前基于模块的简单配置示例的略微修改:
需要注意的是，'应用程序' 代码并不关心是否有多个日志处理器。示例中所做的改变只是添加和配置了一个新的名为 fh 的日志处理器。
在编写和测试应用程序时，能够创建带有更高或更低消息等级的过滤器的日志处理器是非常有用的。为了避免过多地使用 print 语句去调试，请使用 logger.debug ：它不像 print 语句需要你不得不在调试结束后注释或删除掉，logger.debug 语句可以在源代码中保持不变，在你再一次需要它之前保持无效。那时，唯一需要改变的是修改日志记录器和/或日志处理器的消息等级，以进行调试。
假设有这样一种情况，你需要将日志按不同的格式和不同的情况存储在控制台和文件中。比如说想把日志等级为DEBUG或更高的消息记录于文件中，而把那些等级为INFO或更高的消息输出在控制台。而且记录在文件中的消息格式需要包含时间戳，打印在控制台的不需要。以下示例展示了如何做到:
当运行后，你会看到控制台如下所示
而在文件中会看到像这样
正如你所看到的，DEBUG级别的消息只展示在文件中，而其他消息两个地方都会输出。
这个示例只演示了在控制台和文件中去记录日志，但你也可以自由组合任意数量的日志处理器。
以下是在一个模块中使用日志服务器配置的示例:
然后如下的脚本，它接收文件名做为命令行参数，并将该文件以二进制编码的方式传给服务器，做为新的日志服务器配置:
有时候需要让日志处理程序在不阻塞当前正在记录线程的情况下完成工作。 这在Web应用程序中很常见，当然也会在其他场景中出现。
一个常见的缓慢行为是 SMTPHandler: 由于开发者无法控制的多种原因（例如，性能不佳的邮件或网络基础架构），发送电子邮件可能需要很长时间。 其实几乎所有基于网络的处理程序都可能造成阻塞：即便是 SocketHandler 也可能在底层进行 DNS 查询，这太慢了（这个查询会深入至套接字代码，位于 Python 层之下，这是不受开发者控制的）。
一种解决方案是分成两部分去处理。第一部分，针对那些对性能有要求的关键线程的日志记录附加一个 QueueHandler。 日志记录器只需简单写入队列，该队列可以设置一个足够大的容量甚至不设置容量上限。通常写入队列是一个快速的操作，即使可能需要在代码中去捕获例如 queue.Full 等异常。 如果你是一名处理关键线程的开发者，请务必记录这些信息 (包括建议只为日志处理器附加 QueueHandlers) 以便于其他开发者使用你的代码。
解决方案的另一部分是 QueueListener，它被设计用来作为 QueueHandler 的对应。 QueueListener 非常简单：向其传入一个队列和一些处理句柄，它会启动一个内部线程来监听从 QueueHandlers (或任何其他可用的 LogRecords 源) 发送过来的 LogRecords 队列。 LogRecords 会从队列中被移除，并被传递给句柄进行处理。
使用一个单独的类 QueueListener 优点是可以使用同一个实例去服务于多个``QueueHandlers``。这样会更节省资源，否则每个处理程序都占用一个线程没有任何益处。
以下是使用了这样两个类的示例(省略了导入语句):
在运行后会产生:
在 3.5 版更改: 在 Python 3.5 之前，QueueListener 总是把从队列中接收的每个消息都传给它初始化的日志处理程序。(这是因为它会假设过滤级别总是在队列的另一侧去设置的。) 从 Python 3.5 开始，可以通过在监听器构造函数中添加一个参数 respect_handler_level=True 改变这种情况。当这样设置时，监听器会比较每条消息的等级和日志处理器中设置的等级，只把需要传递的消息传给对应的日志处理器。
如果你想在网络上发送日志，并在接收端处理它们。一个简单的方式是通过附加一个 SocketHandler 的实例在发送端的根日志处理器中:
在接收端，你可以使用 socketserver 模块设置一个接收器。这里是一个基础示例:
首先运行服务端，然后是客户端。在客户端，没有什么内容会打印在控制台中；在服务端，你应该会看到如下内容：
请注意，在某些情况下序列化会存在一些安全。如果这影响到你，那么你可以通过覆盖 makePickle() 方法，使用自己的实现来解决，并调整上述脚本也使用覆盖后的序列化方法。
有时，除了传递给日志记录器调用的参数外，我们还希望日志记录中包含上下文信息。例如，有一个网络应用，可能需要记录一些特殊的客户端信息在日志中（比如客户端的用户名、IP地址等）。虽然你可以通过设置额外的参数去达到这个目的，但这种方式不一定方便。或者你可能想到在每个连接的基础上创建一个 Logger 的实例，但这些实例是不会被垃圾回收的，这在练习中也许不是问题，但当 Logger 的实例数量取决于你应用程序中想记录的细致程度时，如果 Logger 的实例数量不受限制的话，将会变得难以管理。
一个传递上下文信息和日志事件信息的简单办法是使用类 LoggerAdapter。 这个类设计的像 Logger，所以可以直接调用 debug()、info()、 warning()、 error()、exception()、 critical() 和 log()。 这些方法在对应的 Logger 中使用相同的签名，所以可以交替使用两种类型的实例。
当你创建一个 LoggerAdapter 的实例时，你会传入一个 Logger 的实例和一个包含了上下文信息的字典对象。当你调用一个 LoggerAdapter 实例的方法时，它会把调用委托给内部的 Logger 的实例，并为其整理相关的上下文信息。这是 LoggerAdapter 的一个代码片段:
LoggerAdapter 的 process() 方法是将上下文信息添加到日志的输出中。 它传入日志消息和日志调用的关键字参数，并传回（隐式的）这些修改后的内容去调用底层的日志记录器。此方法的默认参数只是一个消息字段，但留有一个 'extra' 的字段作为关键字参数传给构造器。当然，如果你在调用适配器时传入了一个 'extra' 字段的参数，它会被静默覆盖。
使用 'extra' 的优点是这些键值对会被传入 LogRecord 实例的 __dict__ 中，让你通过 Formatter 的实例直接使用定制的字符串，实例能找到这个字典类对象的键。 如果你需要一个其他的方法，比如说，想要在消息字符串前后增加上下文信息，你只需要创建一个 LoggerAdapter 的子类，并覆盖它的 process() 方法来做你想做的事情，以下是一个简单的示例:
你可以这样使用:
然后，你记录在适配器中的任何事件消息前将添加``some_conn_id``的值。
你不需要将一个实际的字典传递给 LoggerAdapter-你可以传入一个实现了``__getitem__`` 和``__iter__``的类的实例，这样它就像是一个字典。这对于你想动态生成值（而字典中的值往往是常量）将很有帮助。
你也可以使用一个用户定义的类 Filter 在日志输出中添加上下文信息。Filter 的实例是被允许修改传入的 LogRecords，包括添加其他的属性，然后可以使用合适的格式化字符串输出，或者可以使用一个自定义的类 Formatter。
例如，在一个web应用程序中，正在处理的请求（或者至少是请求的一部分），可以存储在一个线程本地 (threading.local) 变量中，然后从``Filter`` 中去访问。请求中的信息，如IP地址和用户名将被存储在``LogRecord``中，使用上例 LoggerAdapter 中的 'ip' 和 'user' 属性名。在这种情况下，可以使用相同的格式化字符串来得到上例中类似的输出结果。这是一段示例代码:
在运行时，产生如下内容:
尽管 logging 是线程安全的，将单个进程中的多个线程日志记录至单个文件也 是 受支持的，但将 多个进程 中的日志记录至单个文件则 不是 受支持的，因为在 Python 中并没有在多个进程中实现对单个文件访问的序列化的标准方案。 如果你需要将多个进程中的日志记录至单个文件，有一个方案是让所有进程都将日志记录至一个 SocketHandler，然后用一个实现了套接字服务器的单独进程一边从套接字中读取一边将日志记录至文件。 （如果愿意的话，你可以在一个现有进程中专门开一个线程来执行此项功能。） 这一部分 文档对此方式有更详细的介绍，并包含一个可用的套接字接收器，你自己的应用可以在此基础上进行适配。
You could also write your own handler which uses the Lock
class from the multiprocessing module to serialize access to the
file from your processes. The existing FileHandler and subclasses do
not make use of multiprocessing at present, though they may do so in the
future. Note that at present, the multiprocessing module does not provide
working lock functionality on all platforms (see
https://bugs.python.org/issue3770).
或者，你也可以使用 Queue 和 QueueHandler 将所有的日志事件发送至你的多进程应用的一个进程中。 以下示例脚本演示了如何执行此操作。 在示例中，一个单独的监听进程负责监听其他进程的日志事件，并根据自己的配置记录。 尽管示例只演示了这种方法（例如你可能希望使用单独的监听线程而非监听进程 —— 它们的实现是类似的），但你也可以在应用程序的监听进程和其他进程使用不同的配置，它可以作为满足你特定需求的一个基础:
上面脚本的一个变种，仍然在主进程中记录日志，但使用一个单独的线程:
这段变种的代码展示了如何使用特定的日志记录配置 - 例如``foo``记录器使用了特殊的处理程序，将 foo 子系统中所有的事件记录至一个文件 mplog-foo.log。在主进程（即使是在工作进程中产生的日志事件）的日志记录机制中将直接使用恰当的配置。
If you want to use concurrent.futures.ProcessPoolExecutor to start
your worker processes, you need to create the queue slightly differently.
Instead of
you should use
and you can then replace the worker creation from this:
to this (remembering to first import concurrent.futures):
有时，你希望当日志文件不断记录增长至一定大小时，打开一个新的文件接着记录。 你可能希望只保留一定数量的日志文件，当不断的创建文件到达该数量时，又覆盖掉最开始的文件形成循环。 对于这种使用场景，日志包提供了 RotatingFileHandler:
结果应该是6个单独的文件，每个文件都包含了应用程序的部分历史日志:
最新的文件始终是:file:logging_rotatingfile_example.out，每次到达大小限制时，都会使用后缀``.1``重命名。每个现有的备份文件都会被重命名并增加其后缀（例如``.1`` 变为``.2``），而``.6``文件会被删除掉。
显然，这个例子将日志长度设置得太小，这是一个极端的例子。 你可能希望将 maxBytes 设置为一个合适的值。
当日志模块被添加至 Python 标准库时，只有一种格式化消息内容的方法即 %-formatting。 在那之后，Python 又增加了两种格式化方法: string.Template (在 Python 2.4 中新增) 和 str.format() (在 Python 2.6 中新增)。
日志（从 3.2 开始）为这两种格式化方式提供了更多支持。Formatter 类可以添加一个额外的可选关键字参数 style。它的默认值是 '%'，其他的值 '{' 和 '$' 也支持，对应了其他两种格式化样式。其保持了向后兼容（如您所愿），但通过显示指定样式参数，你可以指定格式化字符串的方式是使用 str.format() 或 string.Template。 这里是一个控制台会话的示例，展示了这些方式：
请注意最终输出到日志的消息格式完全独立于单条日志消息的构造方式。 它仍然可以使用 %-formatting，如下所示:
Logging calls (logger.debug(), logger.info() etc.) only take
positional parameters for the actual logging message itself, with keyword
parameters used only for determining options for how to handle the actual
logging call (e.g. the exc_info keyword parameter to indicate that
traceback information should be logged, or the extra keyword parameter
to indicate additional contextual information to be added to the log). So
you cannot directly make logging calls using str.format() or
string.Template syntax, because internally the logging package
uses %-formatting to merge the format string and the variable arguments.
There would be no changing this while preserving backward compatibility, since
all logging calls which are out there in existing code will be using %-format
strings.
There is, however, a way that you can use {}- and $- formatting to construct
your individual log messages. Recall that for a message you can use an
arbitrary object as a message format string, and that the logging package will
call str() on that object to get the actual format string. Consider the
following two classes:
Either of these can be used in place of a format string, to allow {}- or
$-formatting to be used to build the actual "message" part which appears in the
formatted log output in place of "%(message)s" or "{message}" or "$message".
It's a little unwieldy to use the class names whenever you want to log
something, but it's quite palatable if you use an alias such as __ (double
underscore --- not to be confused with _, the single underscore used as a
synonym/alias for gettext.gettext() or its brethren).
The above classes are not included in Python, though they're easy enough to
copy and paste into your own code. They can be used as follows (assuming that
they're declared in a module called wherever):
While the above examples use print() to show how the formatting works, you
would of course use logger.debug() or similar to actually log using this
approach.
One thing to note is that you pay no significant performance penalty with this
approach: the actual formatting happens not when you make the logging call, but
when (and if) the logged message is actually about to be output to a log by a
handler. So the only slightly unusual thing which might trip you up is that the
parentheses go around the format string and the arguments, not just the format
string. That's because the __ notation is just syntax sugar for a constructor
call to one of the XXXMessage classes.
If you prefer, you can use a LoggerAdapter to achieve a similar effect
to the above, as in the following example:
The above script should log the message Hello, world! when run with
Python 3.2 or later.
Every logging event is represented by a LogRecord instance.
When an event is logged and not filtered out by a logger's level, a
LogRecord is created, populated with information about the event and
then passed to the handlers for that logger (and its ancestors, up to and
including the logger where further propagation up the hierarchy is disabled).
Before Python 3.2, there were only two places where this creation was done:
Logger.makeRecord(), which is called in the normal process of
logging an event. This invoked LogRecord directly to create an
instance.
makeLogRecord(), which is called with a dictionary containing
attributes to be added to the LogRecord. This is typically invoked when a
suitable dictionary has been received over the network (e.g. in pickle form
via a SocketHandler, or in JSON form via an
HTTPHandler).
This has usually meant that if you need to do anything special with a
LogRecord, you've had to do one of the following.
Create your own Logger subclass, which overrides
Logger.makeRecord(), and set it using setLoggerClass()
before any loggers that you care about are instantiated.
Add a Filter to a logger or handler, which does the
necessary special manipulation you need when its
filter() method is called.
The first approach would be a little unwieldy in the scenario where (say)
several different libraries wanted to do different things. Each would attempt
to set its own Logger subclass, and the one which did this last would
win.
The second approach works reasonably well for many cases, but does not allow
you to e.g. use a specialized subclass of LogRecord. Library
developers can set a suitable filter on their loggers, but they would have to
remember to do this every time they introduced a new logger (which they would
do simply by adding new packages or modules and doing
at module level). It's probably one too many things to think about. Developers
could also add the filter to a NullHandler attached to their
top-level logger, but this would not be invoked if an application developer
attached a handler to a lower-level library logger --- so output from that
handler would not reflect the intentions of the library developer.
In Python 3.2 and later, LogRecord creation is done through a
factory, which you can specify. The factory is just a callable you can set with
setLogRecordFactory(), and interrogate with
getLogRecordFactory(). The factory is invoked with the same
signature as the LogRecord constructor, as LogRecord
is the default setting for the factory.
This approach allows a custom factory to control all aspects of LogRecord
creation. For example, you could return a subclass, or just add some additional
attributes to the record once created, using a pattern similar to this:
This pattern allows different libraries to chain factories together, and as
long as they don't overwrite each other's attributes or unintentionally
overwrite the attributes provided as standard, there should be no surprises.
However, it should be borne in mind that each link in the chain adds run-time
overhead to all logging operations, and the technique should only be used when
the use of a Filter does not provide the desired result.
You can use a QueueHandler subclass to send messages to other kinds
of queues, for example a ZeroMQ 'publish' socket. In the example below,the
socket is created separately and passed to the handler (as its 'queue'):
Of course there are other ways of organizing this, for example passing in the
data needed by the handler to create the socket:
You can also subclass QueueListener to get messages from other kinds
of queues, for example a ZeroMQ 'subscribe' socket. Here's an example:
参见
日志记录模块的 API 参考。
日志记录模块的配置 API 。
日志记录模块附带的有用处理器。
A basic logging tutorial
A more advanced logging tutorial
Below is an example of a logging configuration dictionary - it's taken from
the documentation on the Django project.
This dictionary is passed to dictConfig() to put the configuration into effect:
For more information about this configuration, you can see the relevant
section
of the Django documentation.
An example of how you can define a namer and rotator is given in the following
snippet, which shows zlib-based compression of the log file:
These are not "true" .gz files, as they are bare compressed data, with no
"container" such as you’d find in an actual gzip file. This snippet is just
for illustration purposes.
The following working example shows how logging can be used with multiprocessing
using configuration files. The configurations are fairly simple, but serve to
illustrate how more complex ones could be implemented in a real multiprocessing
scenario.
In the example, the main process spawns a listener process and some worker
processes. Each of the main process, the listener and the workers have three
separate configurations (the workers all share the same configuration). We can
see logging in the main process, how the workers log to a QueueHandler and how
the listener implements a QueueListener and a more complex logging
configuration, and arranges to dispatch events received via the queue to the
handlers specified in the configuration. Note that these configurations are
purely illustrative, but you should be able to adapt this example to your own
scenario.
Here's the script - the docstrings and the comments hopefully explain how it
works:
RFC 5424 requires that a
Unicode message be sent to a syslog daemon as a set of bytes which have the
following structure: an optional pure-ASCII component, followed by a UTF-8 Byte
Order Mark (BOM), followed by Unicode encoded using UTF-8. (See the
relevant section of the specification.)
In Python 3.1, code was added to
SysLogHandler to insert a BOM into the message, but
unfortunately, it was implemented incorrectly, with the BOM appearing at the
beginning of the message and hence not allowing any pure-ASCII component to
appear before it.
As this behaviour is broken, the incorrect BOM insertion code is being removed
from Python 3.2.4 and later. However, it is not being replaced, and if you
want to produce RFC 5424-compliant messages which include a BOM, an optional
pure-ASCII sequence before it and arbitrary Unicode after it, encoded using
UTF-8, then you need to do the following:
Attach a Formatter instance to your
SysLogHandler instance, with a format string
such as:
The Unicode code point U+FEFF, when encoded using UTF-8, will be
encoded as a UTF-8 BOM -- the byte-string b'\xef\xbb\xbf'.
Replace the ASCII section with whatever placeholders you like, but make sure
that the data that appears in there after substitution is always ASCII (that
way, it will remain unchanged after UTF-8 encoding).
Replace the Unicode section with whatever placeholders you like; if the data
which appears there after substitution contains characters outside the ASCII
range, that's fine -- it will be encoded using UTF-8.
The formatted message will be encoded using UTF-8 encoding by
SysLogHandler. If you follow the above rules, you should be able to produce
RFC 5424-compliant messages. If you don't, logging may not complain, but your
messages will not be RFC 5424-compliant, and your syslog daemon may complain.
Although most logging messages are intended for reading by humans, and thus not
readily machine-parseable, there might be circumstances where you want to output
messages in a structured format which is capable of being parsed by a program
(without needing complex regular expressions to parse the log message). This is
straightforward to achieve using the logging package. There are a number of
ways in which this could be achieved, but the following is a simple approach
which uses JSON to serialise the event in a machine-parseable manner:
If the above script is run, it prints:
Note that the order of items might be different according to the version of
Python used.
If you need more specialised processing, you can use a custom JSON encoder,
as in the following complete example:
When the above script is run, it prints:
Note that the order of items might be different according to the version of
Python used.
There are times when you want to customize logging handlers in particular ways,
and if you use dictConfig() you may be able to do this without
subclassing. As an example, consider that you may want to set the ownership of a
log file. On POSIX, this is easily done using shutil.chown(), but the file
handlers in the stdlib don't offer built-in support. You can customize handler
creation using a plain function such as:
You can then specify, in a logging configuration passed to dictConfig(),
that a logging handler be created by calling this function:
In this example I am setting the ownership using the pulse user and group,
just for the purposes of illustration. Putting it together into a working
script, chowntest.py:
To run this, you will probably need to run as root:
Note that this example uses Python 3.3 because that's where shutil.chown()
makes an appearance. This approach should work with any Python version that
supports dictConfig() - namely, Python 2.7, 3.2 or later. With pre-3.3
versions, you would need to implement the actual ownership change using e.g.
os.chown().
In practice, the handler-creating function may be in a utility module somewhere
in your project. Instead of the line in the configuration:
you could use e.g.:
where project.util can be replaced with the actual name of the package
where the function resides. In the above working script, using
'ext://__main__.owned_file_handler' should work. Here, the actual callable
is resolved by dictConfig() from the ext:// specification.
This example hopefully also points the way to how you could implement other
types of file change - e.g. setting specific POSIX permission bits - in the
same way, using os.chmod().
Of course, the approach could also be extended to types of handler other than a
FileHandler - for example, one of the rotating file handlers,
or a different type of handler altogether.
In Python 3.2, the Formatter gained a style keyword
parameter which, while defaulting to % for backward compatibility, allowed
the specification of { or $ to support the formatting approaches
supported by str.format() and string.Template. Note that this
governs the formatting of logging messages for final output to logs, and is
completely orthogonal to how an individual logging message is constructed.
Logging calls (debug(), info() etc.) only take
positional parameters for the actual logging message itself, with keyword
parameters used only for determining options for how to handle the logging call
(e.g. the exc_info keyword parameter to indicate that traceback information
should be logged, or the extra keyword parameter to indicate additional
contextual information to be added to the log). So you cannot directly make
logging calls using str.format() or string.Template syntax,
because internally the logging package uses %-formatting to merge the format
string and the variable arguments. There would no changing this while preserving
backward compatibility, since all logging calls which are out there in existing
code will be using %-format strings.
There have been suggestions to associate format styles with specific loggers,
but that approach also runs into backward compatibility problems because any
existing code could be using a given logger name and using %-formatting.
For logging to work interoperably between any third-party libraries and your
code, decisions about formatting need to be made at the level of the
individual logging call. This opens up a couple of ways in which alternative
formatting styles can be accommodated.
In Python 3.2, along with the Formatter changes mentioned
above, the logging package gained the ability to allow users to set their own
LogRecord subclasses, using the setLogRecordFactory() function.
You can use this to set your own subclass of LogRecord, which does the
Right Thing by overriding the getMessage() method. The base
class implementation of this method is where the msg % args formatting
happens, and where you can substitute your alternate formatting; however, you
should be careful to support all formatting styles and allow %-formatting as
the default, to ensure interoperability with other code. Care should also be
taken to call str(self.msg), just as the base implementation does.
Refer to the reference documentation on setLogRecordFactory() and
LogRecord for more information.
There is another, perhaps simpler way that you can use {}- and $- formatting to
construct your individual log messages. You may recall (from
使用任意对象作为消息) that when logging you can use an arbitrary
object as a message format string, and that the logging package will call
str() on that object to get the actual format string. Consider the
following two classes:
Either of these can be used in place of a format string, to allow {}- or
$-formatting to be used to build the actual "message" part which appears in the
formatted log output in place of “%(message)s” or “{message}” or “$message”.
If you find it a little unwieldy to use the class names whenever you want to log
something, you can make it more palatable if you use an alias such as M or
_ for the message (or perhaps __, if you are using _ for
localization).
Examples of this approach are given below. Firstly, formatting with
str.format():
Secondly, formatting with string.Template:
One thing to note is that you pay no significant performance penalty with this
approach: the actual formatting happens not when you make the logging call, but
when (and if) the logged message is actually about to be output to a log by a
handler. So the only slightly unusual thing which might trip you up is that the
parentheses go around the format string and the arguments, not just the format
string. That’s because the __ notation is just syntax sugar for a constructor
call to one of the XXXMessage classes shown above.
You can configure filters using dictConfig(), though it
might not be obvious at first glance how to do it (hence this recipe). Since
Filter is the only filter class included in the standard
library, and it is unlikely to cater to many requirements (it's only there as a
base class), you will typically need to define your own Filter
subclass with an overridden filter() method. To do this,
specify the () key in the configuration dictionary for the filter,
specifying a callable which will be used to create the filter (a class is the
most obvious, but you can provide any callable which returns a
Filter instance). Here is a complete example:
This example shows how you can pass configuration data to the callable which
constructs the instance, in the form of keyword parameters. When run, the above
script will print:
which shows that the filter is working as configured.
A couple of extra points to note:
If you can't refer to the callable directly in the configuration (e.g. if it
lives in a different module, and you can't import it directly where the
configuration dictionary is), you can use the form ext://... as described
in 访问外部对象. For example, you could have used
the text 'ext://__main__.MyFilter' instead of MyFilter in the above
example.
As well as for filters, this technique can also be used to configure custom
handlers and formatters. See 用户定义对象 for more
information on how logging supports using user-defined objects in its
configuration, and see the other cookbook recipe Customizing handlers with dictConfig() above.
There might be times when you want to do customized exception formatting - for
argument's sake, let's say you want exactly one line per logged event, even
when exception information is present. You can do this with a custom formatter
class, as shown in the following example:
When run, this produces a file with exactly two lines:
While the above treatment is simplistic, it points the way to how exception
information can be formatted to your liking. The traceback module may be
helpful for more specialized needs.
There might be situations when it is desirable to have logging messages rendered
in an audible rather than a visible format. This is easy to do if you have
text-to-speech (TTS) functionality available in your system, even if it doesn't have
a Python binding. Most TTS systems have a command line program you can run, and
this can be invoked from a handler using subprocess. It's assumed here
that TTS command line programs won't expect to interact with users or take a
long time to complete, and that the frequency of logged messages will be not so
high as to swamp the user with messages, and that it's acceptable to have the
messages spoken one at a time rather than concurrently, The example implementation
below waits for one message to be spoken before the next is processed, and this
might cause other handlers to be kept waiting. Here is a short example showing
the approach, which assumes that the espeak TTS package is available:
When run, this script should say "Hello" and then "Goodbye" in a female voice.
The above approach can, of course, be adapted to other TTS systems and even
other systems altogether which can process messages via external programs run
from a command line.
在某些情况下，你可能希望在临时区域中记录日志消息，并且只在发生某种特定的情况下才输出它们。 例如，你可能希望起始在函数中记录调试事件，如果函数执行完成且没有错误，你不希望输出收集的调试信息以避免造成日志混乱，但如果出现错误，那么你希望所有调试以及错误消息被输出。
下面是一个示例，展示如何在你的日志记录函数上使用装饰器以实现这一功能。该示例使用 logging.handlers.MemoryHandler ，它允许缓冲已记录的事件直到某些条件发生，缓冲的事件才会被刷新（flushed） - 传递给另一个处理程序（ target handler）进行处理。 默认情况下， MemoryHandler 在其缓冲区被填满时被刷新，或者看到一个级别大于或等于指定阈值的事件。 如果想要自定义刷新行为，你可以通过更专业的 MemoryHandler 子类来使用这个秘诀。
这个示例脚本有一个简单的函数 foo ，它只是在所有的日志级别中循环运行，写到 sys.stderr ，说明它要记录在哪个级别上，然后在这个级别上实际记录一个消息。你可以给 foo 传递一个参数，如果为 true ，它将在ERROR和CRITICAL级别记录，否则，它只在DEBUG、INFO和WARNING级别记录。
脚本只是使用了一个装饰器来装饰 foo，这个装饰器将记录执行所需的条件。装饰器使用一个记录器作为参数，并在调用被装饰的函数期间附加一个内存处理程序。装饰器可以使用目标处理程序、记录级别和缓冲区的容量（缓冲记录的数量）来附加参数。这些参数分别默认为写入``sys.stderr`` 的 StreamHandler ， logging.ERROR 和 100。
以下是脚本：
运行此脚本时，应看到以下输出：
如你所见，实际日志记录输出仅在消息等级为ERROR或更高的事件时发生，但在这种情况下，任何之前较低消息等级的事件还会被记录。
你当然可以使用传统的装饰方法:
有时候，你希望使用UTC来格式化时间，这可以通过使用一个类来实现，例如`UTCFormatter`，如下所示：
然后你可以在你的代码中使用 UTCFormatter，而不是 Formatter。 如果你想通过配置来实现这一功能，你可以使用 dictConfig() API 来完成，该方法在以下完整示例中展示:
脚本会运行输出类似下面的内容:
展示了如何将时间格式化为本地时间和UTC两种形式，其中每种形式对应一个日志处理器 。
有时候，我们需要暂时更改日志配置，并在执行某些操作后将其还原。为此，上下文管理器是实现保存和恢复日志上下文的最明显的方式。这是一个关于上下文管理器的简单例子，它允许你在上下文管理器的作用域内更改日志记录等级以及增加日志处理器：
如果指定上下文管理器的日志记录等级属性，则在上下文管理器的with语句所涵盖的代码中，日志记录器的记录等级将临时设置为上下文管理器所配置的日志记录等级。 如果指定上下文管理的日志处理器属性，则该句柄在进入上下文管理器的上下文时添加到记录器中，并在退出时被删除。 如果你再也不需要该日志处理器时，你可以让上下文管理器在退出上下文管理器的上下文时关闭它。
为了说明它是如何工作的，我们可以在上面添加以下代码块:
我们最初设置日志记录器的消息等级为 INFO，因此消息#1出现，消息#2没有出现。在接下来的 with``代码块中我们暂时将消息等级变更为 ``DEBUG，从而消息 #3 出现。在这一代码块退出后，日志记录器的消息等级恢复为 INFO，从而消息 #4 没有出现。在下一个 with 代码块中，我们再一次将设置消息等级设置为 DEBUG，同时添加一个将消息写入 sys.stdout 的日志处理器。因此，消息#5在控制台出现两次 (分别通过 stderr 和 stdout)。在 with 语句完成后，状态与之前一样，因此消息 #6 出现（类似消息 #1），而消息 #7 没有出现（类似消息 #2）。
如果我们运行生成的脚本，结果如下：
我们将``stderr``标准错误重定向到``/dev/null``，我再次运行生成的脚步，唯一被写入``stdout``标准输出的消息，即我们所能看见的消息，如下：
再一次，将 stdout 标准输出重定向到 /dev/null，我获得如下结果：
在这种情况下，与预期一致，打印到 stdout 标准输出的消息＃5不会出现。
当然，这里描述的方法可以被推广，例如临时附加日志记录过滤器。 请注意，上面的代码适用于Python 2以及Python 3。
Here's an example which shows how you can:
Use a logging level based on command-line arguments
Dispatch to multiple subcommands in separate files, all logging at the same
level in a consistent way
Make use of simple, minimal configuration
Suppose we have a command-line application whose job is to stop, start or
restart some services. This could be organised for the purposes of illustration
as a file app.py that is the main script for the application, with individual
commands implemented in start.py, stop.py and restart.py. Suppose
further that we want to control the verbosity of the application via a
command-line argument, defaulting to logging.INFO. Here's one way that
app.py could be written:
And the start, stop and restart commands can be implemented in
separate modules, like so for starting:
and thus for stopping:
and similarly for restarting:
If we run this application with the default log level, we get output like this:
The first word is the logging level, and the second word is the module or
package name of the place where the event was logged.
If we change the logging level, then we can change the information sent to the
log. For example, if we want more information:
And if we want less:
In this case, the commands don't print anything to the console, since nothing
at WARNING level or above is logged by them.
A question that comes up from time to time is about how to log to a GUI
application. The Qt framework is a popular
cross-platform UI framework with Python bindings using PySide2 or PyQt5 libraries.
The following example shows how to log to a Qt GUI. This introduces a simple
QtHandler class which takes a callable, which should be a slot in the main
thread that does GUI updates. A worker thread is also created to show how you
can log to the GUI from both the UI itself (via a button for manual logging)
as well as a worker thread doing work in the background (here, just logging
messages at random levels with random short delays in between).
The worker thread is implemented using Qt's QThread class rather than the
threading module, as there are circumstances where one has to use
QThread, which offers better integration with other Qt components.
The code should work with recent releases of either PySide2 or PyQt5.
You should be able to adapt the approach to earlier versions of Qt. Please
refer to the comments in the code snippet for more detailed information.
日志常用指引
正则表达式HOWTO
</body></doc>